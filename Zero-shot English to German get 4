from datasets import load_dataset
from sacrebleu import BLEU
from bert_score import score as bert_score
import openai
import time

openai.api_key = "sk-apikey"

# Load the dataset
dataset = load_dataset("wmt14", "de-en", split="test")

# Set the batch size and delay between batches
batch_size = 1000
delay_seconds = 30

translations = []
references = [example["translation"]["de"] for example in dataset]

for i in range(0, len(dataset), batch_size):
    batch = dataset.select(range(i, min(i + batch_size, len(dataset))))
    for example in batch:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Translate the following text from English to German:"},
                {"role": "user", "content": example["translation"]["en"]},
            ],
            max_tokens=150,
            temperature=0.7,
            top_p=1,
            n=1,
        )
        translation = response.choices[0].message["content"].strip()
        translations.append(translation)

        # Save the translated text to a file
        with open("translationsDEEN4.txt", "a") as file:
            file.write(f"Original English: {example['translation']['en']}\n")
            file.write(f"Translated German: {translation}\n\n")

    # Add a delay between batches
    if i + batch_size < len(dataset):
        print(f"Translated {i + batch_size} sentences. Waiting for {delay_seconds} seconds...")
        time.sleep(delay_seconds)

# Calculate BLEU score
bleu = BLEU()
score = bleu.corpus_score(translations, [references])
print(f"BLEU score: {score.score}")

# Calculate BERTScore for all translations against all references
P, R, F1 = bert_score(translations, references, lang="de", verbose=True)
bertscore = F1.mean().item()


with open("scoresEN_DE4.txt", "w") as file:
    file.write(f"BLEU score: {score.score}\n")
    file.write(f"BERTScore: {bertscore}\n")
